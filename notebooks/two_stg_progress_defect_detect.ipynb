{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Two-Stage PCB Defect Detection Pipeline\n\n# This notebook implements a hybrid approach for PCB defect detection:\n# 1. Stage 1: Train or fine-tune a CNN model on Keras datasets + PCB images\n# 2. Stage 2: Integrate with zero-shot learning for enhanced defect detection\n#\n# The approach combines traditional supervised learning with zero-shot capabilities\n# to create a more robust PCB inspection system.\n\nimport os\nimport sys\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import MobileNetV2, ResNet50V2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport torch\nfrom transformers import CLIPProcessor, CLIPModel\nfrom typing import List, Dict, Any, Union, Optional, Tuple\nimport time\nimport datetime\nimport glob\nimport random\nimport cv2\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom google.colab import drive\n\n# Enable showing images in the notebook\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (12, 8)  # Set default figure size\n\n# Check hardware availability\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"Torch version:\", torch.__version__)\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(\"PyTorch CUDA Available: \", torch.cuda.is_available())\n\n# Mount Google Drive (for storing/reading PCB images and models)\ndrive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Directory Setup and Data Management"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class PCBDataManager:\n    \"\"\"Manages PCB image data for both CNN training and zero-shot detection.\"\"\"\n    \n    def __init__(self, base_dir='/content/drive/MyDrive/PCB_Defect_Detection'):\n        \"\"\"\n        Initialize the PCB data manager with directories for all project assets.\n        \n        Args:\n            base_dir: Base directory for the project in Google Drive\n        \"\"\"\n        self.base_dir = base_dir\n        \n        # Create directory structure\n        self.dirs = {\n            'data': os.path.join(base_dir, 'data'),\n            'models': os.path.join(base_dir, 'models'),\n            'results': os.path.join(base_dir, 'results'),\n            'temp': os.path.join(base_dir, 'temp')\n        }\n        \n        # Create subdirectories for data\n        self.data_dirs = {\n            'normal': os.path.join(self.dirs['data'], 'normal'),\n            'defective': os.path.join(self.dirs['data'], 'defective'),\n            'test': os.path.join(self.dirs['data'], 'test'),\n            'keras_processed': os.path.join(self.dirs['data'], 'keras_processed')\n        }\n        \n        # Create all directories if they don't exist\n        self._create_directories()\n        \n        # Initialize image path lists\n        self.normal_images = []\n        self.defective_images = []\n        self.test_images = []\n        \n    def _create_directories(self):\n        \"\"\"Create the necessary directory structure.\"\"\"\n        # Create main directories\n        for dir_path in self.dirs.values():\n            os.makedirs(dir_path, exist_ok=True)\n            \n        # Create data subdirectories\n        for dir_path in self.data_dirs.values():\n            os.makedirs(dir_path, exist_ok=True)\n            \n        print(f\"Directory structure created at {self.base_dir}\")\n    \n    def scan_images(self):\n        \"\"\"\n        Scan and list all available PCB images in the normal, defective, \n        and test directories.\n        \n        Returns:\n            Tuple of normal, defective, and test image paths\n        \"\"\"\n        # Find all images in normal and defective directories\n        self.normal_images = self._find_images(self.data_dirs['normal'])\n        self.defective_images = self._find_images(self.data_dirs['defective'])\n        self.test_images = self._find_images(self.data_dirs['test'])\n        \n        print(f\"Found {len(self.normal_images)} normal images\")\n        print(f\"Found {len(self.defective_images)} defective images\")\n        print(f\"Found {len(self.test_images)} test images\")\n        \n        return self.normal_images, self.defective_images, self.test_images\n    \n    def _find_images(self, directory):\n        \"\"\"\n        Find all image files in a directory.\n        \n        Args:\n            directory: Directory to search for images\n            \n        Returns:\n            List of image file paths\n        \"\"\"\n        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n        image_paths = []\n        \n        for ext in image_extensions:\n            image_paths.extend(glob.glob(os.path.join(directory, f\"*{ext}\")))\n            image_paths.extend(glob.glob(os.path.join(directory, f\"*{ext.upper()}\")))\n            \n        return image_paths\n    \n    def prepare_data_for_cnn(self, img_size=(224, 224), batch_size=32, validation_split=0.2):\n        \"\"\"\n        Prepare data for CNN training using Keras ImageDataGenerator.\n        \n        Args:\n            img_size: Target size for the images\n            batch_size: Batch size for training\n            validation_split: Fraction of data to use for validation\n            \n        Returns:\n            train_generator, validation_generator: Data generators for training and validation\n        \"\"\"\n        # Data augmentation for training\n        train_datagen = ImageDataGenerator(\n            rescale=1./255,\n            rotation_range=20,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True,\n            vertical_flip=True,\n            fill_mode='nearest',\n            validation_split=validation_split\n        )\n        \n        # Only rescaling for validation\n        validation_datagen = ImageDataGenerator(\n            rescale=1./255,\n            validation_split=validation_split\n        )\n        \n        # Combined directory with both normal and defective images\n        temp_train_dir = os.path.join(self.dirs['temp'], 'train_data')\n        os.makedirs(os.path.join(temp_train_dir, 'normal'), exist_ok=True)\n        os.makedirs(os.path.join(temp_train_dir, 'defective'), exist_ok=True)\n        \n        # Create symbolic links to original images to avoid duplication\n        # Copy a subset of images to temp directory for training\n        for img_path in self.normal_images[:min(len(self.normal_images), 1000)]:\n            img_name = os.path.basename(img_path)\n            dest_path = os.path.join(temp_train_dir, 'normal', img_name)\n            if not os.path.exists(dest_path):\n                # Use symlink if possible, otherwise copy the file\n                try:\n                    os.symlink(img_path, dest_path)\n                except:\n                    from shutil import copyfile\n                    copyfile(img_path, dest_path)\n                \n        for img_path in self.defective_images[:min(len(self.defective_images), 1000)]:\n            img_name = os.path.basename(img_path)\n            dest_path = os.path.join(temp_train_dir, 'defective', img_name)\n            if not os.path.exists(dest_path):\n                try:\n                    os.symlink(img_path, dest_path)\n                except:\n                    from shutil import copyfile\n                    copyfile(img_path, dest_path)\n        \n        # Create generators for training and validation\n        train_generator = train_datagen.flow_from_directory(\n            temp_train_dir,\n            target_size=img_size,\n            batch_size=batch_size,\n            class_mode='binary',\n            subset='training'\n        )\n        \n        validation_generator = validation_datagen.flow_from_directory(\n            temp_train_dir,\n            target_size=img_size,\n            batch_size=batch_size,\n            class_mode='binary',\n            subset='validation'\n        )\n        \n        print(f\"Training generator created with {train_generator.samples} samples\")\n        print(f\"Validation generator created with {validation_generator.samples} samples\")\n        \n        return train_generator, validation_generator\n    \n    def visualize_sample_images(self, num_samples=5):\n        \"\"\"\n        Visualize sample PCB images from normal and defective categories.\n        \n        Args:\n            num_samples: Number of samples to display from each category\n        \"\"\"\n        fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n        \n        # Display normal samples\n        for i in range(min(num_samples, len(self.normal_images))):\n            img = Image.open(self.normal_images[i])\n            axes[0, i].imshow(np.array(img))\n            axes[0, i].set_title(f\"Normal {i+1}\")\n            axes[0, i].axis('off')\n        \n        # Display defective samples\n        for i in range(min(num_samples, len(self.defective_images))):\n            img = Image.open(self.defective_images[i])\n            axes[1, i].imshow(np.array(img))\n            axes[1, i].set_title(f\"Defective {i+1}\")\n            axes[1, i].axis('off')\n            \n        plt.tight_layout()\n        plt.show()\n        \n    def create_keras_dataset_hybrid(self, keras_dataset='cifar10', num_pcb_samples=500, augmentation_level='minimal'):\n        \"\"\"\n        Create a hybrid dataset that combines Keras dataset with PCB images.\n        This helps with transfer learning from general visual features to PCB-specific features.\n        \n        Args:\n            keras_dataset: Name of the Keras dataset to use ('cifar10' or 'cifar100')\n            num_pcb_samples: Number of PCB samples to include in the hybrid dataset\n            augmentation_level: Level of augmentation to apply ('minimal', 'moderate', 'extensive')\n            \n        Returns:\n            Hybrid dataset for training (x, y)\n        \"\"\"\n        # Load Keras dataset\n        if keras_dataset == 'cifar10':\n            (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n            num_classes = 10\n            # Map CIFAR-10 classes to normal/defective (just for training purposes)\n            # We'll consider: airplane, automobile, bird, cat, deer as \"normal\"\n            # And: dog, frog, horse, ship, truck as \"defective\" (dummy mapping)\n            class_mapping = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n        elif keras_dataset == 'cifar100':\n            (x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n            num_classes = 100\n            # For CIFAR-100, we'll consider first 50 classes as \"normal\" and last 50 as \"defective\"\n            class_mapping = {i: 0 if i < 50 else 1 for i in range(100)}\n        else:\n            raise ValueError(f\"Unsupported dataset: {keras_dataset}\")\n        \n        # Apply class mapping to convert to binary classification\n        y_train_binary = np.array([class_mapping[y[0]] for y in y_train])\n        y_test_binary = np.array([class_mapping[y[0]] for y in y_test])\n        \n        # Resize Keras images to match PCB image size (224, 224)\n        x_train_resized = np.zeros((len(x_train), 224, 224, 3), dtype=np.float32)\n        for i, img in enumerate(x_train):\n            x_train_resized[i] = cv2.resize(img, (224, 224))\n        \n        # Sample PCB images\n        normal_samples = random.sample(self.normal_images, min(num_pcb_samples // 2, len(self.normal_images)))\n        defective_samples = random.sample(self.defective_images, min(num_pcb_samples // 2, len(self.defective_images)))\n        \n        # Load and resize PCB images with proper handling of unusual aspect ratios\n        pcb_images = []\n        pcb_labels = []\n        \n        def process_image_with_aspect_ratio(img_path, target_size=(224, 224)):\n            \"\"\"Process image while preserving aspect ratio\"\"\"\n            # Read image\n            img = cv2.imread(img_path)\n            if img is None:\n                print(f\"Warning: Could not read image {img_path}\")\n                return None\n                \n            # Check aspect ratio\n            height, width = img.shape[0], img.shape[1]\n            aspect_ratio = width / height\n            \n            if aspect_ratio > 3 or aspect_ratio < 1/3:\n                # Very wide or very tall image\n                if width > height:\n                    # Wide image - center crop\n                    center = width // 2\n                    left = max(0, center - height // 2)\n                    img = img[:, left:left+height]\n                else:\n                    # Tall image - center crop\n                    center = height // 2\n                    top = max(0, center - width // 2)\n                    img = img[top:top+width, :]\n            \n            # Resize to target size\n            img = cv2.resize(img, target_size)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n            \n            return img\n        \n        # Process normal images\n        for img_path in normal_samples:\n            img = process_image_with_aspect_ratio(img_path)\n            if img is not None:\n                pcb_images.append(img)\n                pcb_labels.append(0)  # 0 for normal\n        \n        # Process defective images\n        for img_path in defective_samples:\n            img = process_image_with_aspect_ratio(img_path)\n            if img is not None:\n                pcb_images.append(img)\n                pcb_labels.append(1)  # 1 for defective\n        \n        # Convert PCB lists to numpy arrays\n        pcb_images = np.array(pcb_images, dtype=np.float32) if pcb_images else np.array([])\n        pcb_labels = np.array(pcb_labels)\n        \n        if len(pcb_images) == 0:\n            raise ValueError(\"No valid PCB images found. Check image paths and formats.\")\n        \n        # Apply augmentation to PCB images based on level\n        # For keras dataset, we'll use minimal augmentation in early rounds\n        pcb_augmented = self._apply_augmentation_to_numpy(pcb_images, level=augmentation_level)\n        \n        # Normalize all images to [0, 1]\n        x_train_resized = x_train_resized / 255.0\n        pcb_augmented = pcb_augmented / 255.0\n        \n        # Combine datasets (use a portion of CIFAR data)\n        cifar_subset_size = min(10000, len(x_train_resized))\n        hybrid_x = np.concatenate([x_train_resized[:cifar_subset_size], pcb_augmented])\n        hybrid_y = np.concatenate([y_train_binary[:cifar_subset_size], pcb_labels])\n        \n        # Shuffle the combined dataset\n        indices = np.arange(len(hybrid_x))\n        np.random.shuffle(indices)\n        hybrid_x = hybrid_x[indices]\n        hybrid_y = hybrid_y[indices]\n        \n        print(f\"Created hybrid dataset with {len(hybrid_x)} images:\")\n        print(f\" - {cifar_subset_size} images from {keras_dataset}\")\n        print(f\" - {len(pcb_augmented)} PCB images (with {augmentation_level} augmentation)\")\n        print(f\" - Class distribution: {np.sum(hybrid_y == 0)} normal, {np.sum(hybrid_y == 1)} defective\")\n        \n        # Save a few examples of the hybrid dataset for visualization\n        hybrid_examples_dir = os.path.join(self.data_dirs['keras_processed'], 'hybrid_examples')\n        os.makedirs(hybrid_examples_dir, exist_ok=True)\n        \n        for i in range(min(10, len(hybrid_x))):\n            img = (hybrid_x[i] * 255).astype(np.uint8)\n            label = \"normal\" if hybrid_y[i] == 0 else \"defective\"\n            img_path = os.path.join(hybrid_examples_dir, f\"hybrid_{i}_{label}.png\")\n            Image.fromarray(img).save(img_path)\n        \n        return hybrid_x, hybrid_y\n    \n    def _apply_augmentation_to_numpy(self, images, level='minimal'):\n        \"\"\"\n        Apply augmentation to numpy array of images based on level.\n        \n        Args:\n            images: Numpy array of images\n            level: Augmentation level ('minimal', 'moderate', 'extensive')\n            \n        Returns:\n            Augmented images\n        \"\"\"\n        print(f\"Applying {level} augmentation to {len(images)} images...\")\n        \n        # Define augmentation parameters based on level\n        if level == 'minimal':\n            datagen = ImageDataGenerator(\n                rotation_range=10,\n                width_shift_range=0.1,\n                height_shift_range=0.1,\n                zoom_range=0.1,\n                horizontal_flip=True\n            )\n        elif level == 'moderate':\n            datagen = ImageDataGenerator(\n                rotation_range=20,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                horizontal_flip=True,\n                vertical_flip=True,\n                fill_mode='nearest'\n            )\n        elif level == 'extensive':\n            datagen = ImageDataGenerator(\n                rotation_range=40,\n                width_shift_range=0.3,\n                height_shift_range=0.3,\n                shear_range=0.3,\n                zoom_range=0.3,\n                brightness_range=[0.7, 1.3],\n                channel_shift_range=0.3,\n                horizontal_flip=True,\n                vertical_flip=True,\n                fill_mode='nearest'\n            )\n        else:\n            print(f\"Unsupported augmentation level: {level}. Using original images.\")\n            return images\n        \n        # For minimal level, just return original images to retain Keras dataset characteristics\n        if level == 'minimal' and len(images) > 1000:  # Only for large datasets like Keras\n            return images\n        \n        # Create augmented versions (batch size of 1 for simplicity)\n        augmented_images = np.copy(images)\n        for i in range(len(images)):\n            # Get a single image and reshape for ImageDataGenerator\n            img = images[i:i+1]\n            \n            # Generate augmented version\n            aug_iter = datagen.flow(img, batch_size=1)\n            aug_img = next(aug_iter)[0]\n            \n            # Store augmented version\n            augmented_images[i] = aug_img\n        \n        return augmented_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN Model Development (Stage 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class PCBDefectCNN:\n    \"\"\"CNN model for PCB defect detection with transfer learning and progressive training.\"\"\"\n    \n    def __init__(self, base_model='mobilenetv2', img_size=(224, 224, 3)):\n        \"\"\"\n        Initialize the CNN model with the selected architecture.\n        \n        Args:\n            base_model: Base model to use ('mobilenetv2' or 'resnet50v2')\n            img_size: Input image size (height, width, channels)\n        \"\"\"\n        self.img_size = img_size\n        self.base_model_name = base_model\n        self.model = None\n        self.base_model = None\n        self.feature_extractor = None\n        self.history = None\n        self.training_round = 0\n        \n    def build_model(self, num_classes=2, dropout_rate=0.5, fine_tune_layers=0):\n        \"\"\"\n        Build the CNN model using transfer learning from a pre-trained base model.\n        \n        Args:\n            num_classes: Number of output classes (2 for binary classification)\n            dropout_rate: Dropout rate for regularization\n            fine_tune_layers: Number of layers in the base model to fine-tune\n            \n        Returns:\n            Compiled model\n        \"\"\"\n        # Create base model with pretrained weights\n        if self.base_model_name == 'mobilenetv2':\n            self.base_model = MobileNetV2(\n                input_shape=self.img_size,\n                include_top=False,\n                weights='imagenet'\n            )\n        elif self.base_model_name == 'resnet50v2':\n            self.base_model = ResNet50V2(\n                input_shape=self.img_size,\n                include_top=False,\n                weights='imagenet'\n            )\n        else:\n            raise ValueError(f\"Unsupported base model: {self.base_model_name}\")\n        \n        # Freeze base model layers (for transfer learning)\n        self.base_model.trainable = False\n        \n        # Unfreeze the specified number of layers for fine-tuning\n        if fine_tune_layers > 0:\n            for layer in self.base_model.layers[-fine_tune_layers:]:\n                layer.trainable = True\n        \n        # Create the feature extractor model that we'll use for zero-shot integration\n        self.feature_extractor = keras.Model(\n            inputs=self.base_model.input,\n            outputs=self.base_model.output,\n            name=\"pcb_feature_extractor\"\n        )\n        \n        # Build the complete model for classification\n        model = models.Sequential([\n            self.base_model,\n            layers.GlobalAveragePooling2D(),\n            layers.Dense(256, activation='relu'),\n            layers.Dropout(dropout_rate),\n            layers.Dense(128, activation='relu'),\n            layers.Dropout(dropout_rate/2),\n            layers.Dense(num_classes, activation='softmax' if num_classes > 2 else 'sigmoid')\n        ])\n        \n        # Compile model\n        loss_function = 'sparse_categorical_crossentropy' if num_classes > 2 else 'binary_crossentropy'\n        model.compile(\n            optimizer=keras.optimizers.Adam(1e-4),\n            loss=loss_function,\n            metrics=['accuracy']\n        )\n        \n        # Save the model\n        self.model = model\n        self.training_round = 1\n        \n        print(f\"Model built with {self.base_model_name} base:\")\n        print(f\"- Input shape: {self.img_size}\")\n        print(f\"- Output classes: {num_classes}\")\n        print(f\"- Fine-tuned layers: {fine_tune_layers}\")\n        \n        # Print summary of trainable vs non-trainable parameters\n        trainable_count = np.sum([keras.backend.count_params(w) for w in model.trainable_weights])\n        non_trainable_count = np.sum([keras.backend.count_params(w) for w in model.non_trainable_weights])\n        print(f\"- Trainable parameters: {trainable_count:,}\")\n        print(f\"- Non-trainable parameters: {non_trainable_count:,}\")\n        \n        return model\n    \n    def train(self, train_data, validation_data, epochs=20, callbacks=None, class_weights=None):\n        \"\"\"\n        Train the CNN model.\n        \n        Args:\n            train_data: Training data generator or tuple of (x_train, y_train)\n            validation_data: Validation data generator or tuple of (x_val, y_val)\n            epochs: Number of training epochs\n            callbacks: Optional list of Keras callbacks\n            class_weights: Optional class weights for imbalanced datasets\n            \n        Returns:\n            Training history\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not built. Call build_model() first.\")\n        \n        # Create default callbacks if none provided\n        if callbacks is None:\n            callbacks = [\n                keras.callbacks.EarlyStopping(\n                    monitor='val_loss',\n                    patience=5,\n                    restore_best_weights=True\n                ),\n                keras.callbacks.ReduceLROnPlateau(\n                    monitor='val_loss',\n                    factor=0.2,\n                    patience=3,\n                    min_lr=1e-6\n                )\n            ]\n            \n        # Start training\n        start_time = time.time()\n        print(f\"Starting training round {self.training_round} for {epochs} epochs...\")\n        \n        # Check if data is in generator format or numpy arrays\n        if isinstance(train_data, tuple) and len(train_data) == 2:\n            # Numpy arrays\n            x_train, y_train = train_data\n            x_val, y_val = validation_data\n            \n            history = self.model.fit(\n                x_train, y_train,\n                epochs=epochs,\n                validation_data=(x_val, y_val),\n                callbacks=callbacks,\n                class_weight=class_weights,\n                verbose=1\n            )\n        else:\n            # Data generators\n            history = self.model.fit(\n                train_data,\n                epochs=epochs,\n                validation_data=validation_data,\n                callbacks=callbacks,\n                class_weight=class_weights,\n                verbose=1\n            )\n        \n        # Calculate training time\n        train_time = time.time() - start_time\n        print(f\"Training completed in {train_time:.2f} seconds\")\n        \n        # Save history\n        if self.history is None:\n            self.history = history.history\n        else:\n            # Append new history to existing history\n            for key in history.history:\n                if key in self.history:\n                    self.history[key].extend(history.history[key])\n                else:\n                    self.history[key] = history.history[key]\n        \n        return history.history\n    \n    def progressive_train(self, train_data, validation_data, rounds=3, \n                         epochs_per_round=[10, 15, 20], \n                         learning_rates=[1e-4, 1e-5, 1e-6],\n                         unfreeze_percentages=[0, 0.3, 0.5],\n                         data_augmentation_levels=['minimal', 'moderate', 'extensive'],\n                         model_dir=None):\n        \"\"\"\n        Implement progressive training strategy with multiple rounds.\n        Each round unfreezes more layers and uses different learning rates.\n        \n        Args:\n            train_data: Training data generator or tuple of (x_train, y_train) for round 1\n            validation_data: Validation data for round 1\n            rounds: Number of training rounds\n            epochs_per_round: List of epoch counts for each round\n            learning_rates: List of learning rates for each round\n            unfreeze_percentages: Percentage of base model layers to unfreeze in each round\n            data_augmentation_levels: Levels of augmentation for each round\n            model_dir: Directory to save intermediate models\n            \n        Returns:\n            List of training histories for each round\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not built. Call build_model() first.\")\n        \n        if model_dir is not None:\n            os.makedirs(model_dir, exist_ok=True)\n        \n        histories = []\n        \n        # For each training round\n        for round_idx in range(rounds):\n            round_num = round_idx + 1\n            self.training_round = round_num\n            \n            print(f\"\\n===== PROGRESSIVE TRAINING ROUND {round_num}/{rounds} =====\")\n            \n            # 1. Adjust model parameters for this round\n            if round_idx > 0:  # Skip for first round as it's already set up in build_model\n                # Unfreeze layers based on percentage\n                unfreeze_pct = unfreeze_percentages[round_idx]\n                self._unfreeze_layers(unfreeze_pct)\n                \n                # Adjust learning rate\n                lr = learning_rates[round_idx]\n                self._adjust_learning_rate(lr)\n            \n            # 2. Create appropriate data augmentation for this round\n            aug_level = data_augmentation_levels[round_idx]\n            if isinstance(train_data, tuple) and isinstance(validation_data, tuple):\n                # For numpy arrays, we need to create augmented versions\n                x_train, y_train = train_data\n                x_val, y_val = validation_data\n                \n                augmented_train_data = (self._augment_data(x_train, aug_level), y_train)\n                # Don't augment validation data\n                round_train_data = augmented_train_data\n                round_val_data = validation_data\n            else:\n                # For generators, we'd need to adjust the augmentation parameters\n                # This is more complex and would depend on how the generators are created\n                round_train_data = train_data\n                round_val_data = validation_data\n                print(f\"Using existing data generators for round {round_num}\")\n            \n            # 3. Create appropriate callbacks for this round\n            callbacks = [\n                keras.callbacks.EarlyStopping(\n                    monitor='val_loss',\n                    patience=5 + round_idx * 2,  # More patience in later rounds\n                    restore_best_weights=True\n                ),\n                keras.callbacks.ReduceLROnPlateau(\n                    monitor='val_loss',\n                    factor=0.2,\n                    patience=3,\n                    min_lr=learning_rates[-1] / 10  # Even lower min_lr\n                )\n            ]\n            \n            # Add model checkpoint in later rounds\n            if model_dir is not None:\n                checkpoint_path = os.path.join(model_dir, f\"pcb_model_round{round_num}_best.h5\")\n                callbacks.append(\n                    keras.callbacks.ModelCheckpoint(\n                        checkpoint_path,\n                        monitor='val_accuracy',\n                        save_best_only=True,\n                        verbose=1\n                    )\n                )\n            \n            # 4. Train for this round\n            history = self.train(\n                round_train_data,\n                round_val_data,\n                epochs=epochs_per_round[round_idx],\n                callbacks=callbacks\n            )\n            \n            histories.append(history)\n            \n            # 5. Save the model after this round\n            if model_dir is not None:\n                round_model_path = os.path.join(model_dir, f\"pcb_model_round{round_num}\")\n                self.save_model(round_model_path, model_name=f\"round{round_num}\")\n                print(f\"Model saved after round {round_num} to {round_model_path}\")\n            \n            # 6. Update feature extractor after each round\n            self.feature_extractor = keras.Model(\n                inputs=self.model.input,\n                outputs=self.model.get_layer(self.base_model.name).output,\n                name=f\"pcb_feature_extractor_round{round_num}\"\n            )\n        \n        print(\"\\n===== PROGRESSIVE TRAINING COMPLETED =====\")\n        return histories\n    \n    def _unfreeze_layers(self, percentage):\n        \"\"\"\n        Unfreeze a percentage of base model layers from the end.\n        \n        Args:\n            percentage: Percentage of layers to unfreeze (0.0 to 1.0)\n        \"\"\"\n        base_model_layer = None\n        for layer in self.model.layers:\n            if layer.name == self.base_model.name:\n                base_model_layer = layer\n                break\n        \n        if base_model_layer is None:\n            print(\"Warning: Base model not found in model layers\")\n            return\n        \n        # Make base model trainable\n        base_model_layer.trainable = True\n        \n        # Freeze/unfreeze layers based on percentage\n        num_layers = len(base_model_layer.layers)\n        freeze_until = int((1 - percentage) * num_layers)\n        \n        for i, layer in enumerate(base_model_layer.layers):\n            layer.trainable = (i >= freeze_until)\n        \n        # Count trainable parameters\n        trainable_count = np.sum([keras.backend.count_params(w) for w in self.model.trainable_weights])\n        non_trainable_count = np.sum([keras.backend.count_params(w) for w in self.model.non_trainable_weights])\n        \n        print(f\"Unfroze {percentage:.1%} of base model layers ({num_layers - freeze_until}/{num_layers} layers)\")\n        print(f\"- Trainable parameters: {trainable_count:,}\")\n        print(f\"- Non-trainable parameters: {non_trainable_count:,}\")\n    \n    def _adjust_learning_rate(self, learning_rate):\n        \"\"\"\n        Adjust the learning rate of the optimizer.\n        \n        Args:\n            learning_rate: New learning rate\n        \"\"\"\n        if hasattr(self.model.optimizer, 'learning_rate'):\n            self.model.optimizer.learning_rate.assign(learning_rate)\n            print(f\"Learning rate adjusted to {learning_rate}\")\n        else:\n            # Recompile model with new learning rate\n            self.model.compile(\n                optimizer=keras.optimizers.Adam(learning_rate),\n                loss=self.model.loss,\n                metrics=self.model.metrics\n            )\n            print(f\"Model recompiled with learning rate {learning_rate}\")\n    \n    def _augment_data(self, images, level='minimal'):\n        \"\"\"\n        Apply data augmentation to images based on augmentation level.\n        \n        Args:\n            images: Numpy array of images\n            level: Augmentation level ('minimal', 'moderate', or 'extensive')\n            \n        Returns:\n            Augmented images\n        \"\"\"\n        print(f\"Applying {level} data augmentation...\")\n        # For simplicity in this notebook, we'll just return the original images\n        # In a full implementation, you would apply varying degrees of augmentation\n        # based on the specified level\n        return images\n    \n    def save_model(self, model_dir, model_name=None):\n        \"\"\"\n        Save the trained model and feature extractor.\n        \n        Args:\n            model_dir: Directory to save the model\n            model_name: Optional custom model name\n            \n        Returns:\n            Paths to the saved model and feature extractor\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"No model to save. Train the model first.\")\n        \n        # Create timestamp-based model name if not provided\n        if model_name is None:\n            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            model_name = f\"pcb_defect_cnn_{self.base_model_name}_{timestamp}\"\n        \n        # Create model directory\n        model_path = os.path.join(model_dir, model_name)\n        os.makedirs(model_path, exist_ok=True)\n        \n        # Save the full classification model\n        full_model_path = os.path.join(model_path, \"full_model\")\n        self.model.save(full_model_path)\n        \n        # Save the feature extractor model\n        extractor_path = os.path.join(model_path, \"feature_extractor\")\n        self.feature_extractor.save(extractor_path)\n        \n        # Save training history if available\n        if self.history is not None:\n            with open(os.path.join(model_path, 'training_history.json'), 'w') as f:\n                json.dump(self.history, f)\n        \n        print(f\"Model saved to {model_path}\")\n        return full_model_path, extractor_path\n    \n    def load_model(self, model_path):\n        \"\"\"\n        Load a trained model.\n        \n        Args:\n            model_path: Path to the saved model\n            \n        Returns:\n            Loaded model\n        \"\"\"\n        self.model = keras.models.load_model(model_path)\n        \n        # Try to load the feature extractor if it exists\n        extractor_path = os.path.join(os.path.dirname(model_path), \"feature_extractor\")\n        if os.path.exists(extractor_path):\n            self.feature_extractor = keras.models.load_model(extractor_path)\n        \n        print(f\"Model loaded from {model_path}\")\n        return self.model\n    \n    def evaluate(self, test_data, test_labels=None):\n        \"\"\"\n        Evaluate the model on test data.\n        \n        Args:\n            test_data: Test data generator or numpy array\n            test_labels: Optional test labels (if test_data is numpy array)\n            \n        Returns:\n            Evaluation metrics\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"No model to evaluate. Load or train a model first.\")\n        \n        print(\"Evaluating model...\")\n        \n        # Check if data is in generator format or numpy arrays\n        if isinstance(test_data, np.ndarray) and test_labels is not None:\n            # Numpy arrays\n            metrics = self.model.evaluate(test_data, test_labels, verbose=1)\n            y_pred = np.argmax(self.model.predict(test_data), axis=1)\n            \n            # Print classification report\n            print(\"\\nClassification Report:\")\n            print(classification_report(test_labels, y_pred, target_names=['Normal', 'Defective']))\n            \n            # Compute confusion matrix\n            cm = confusion_matrix(test_labels, y_pred)\n            \n            # Plot confusion matrix\n            plt.figure(figsize=(8, 6))\n            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n            plt.title('Confusion Matrix')\n            plt.colorbar()\n            tick_marks = np.arange(2)\n            plt.xticks(tick_marks, ['Normal', 'Defective'], rotation=45)\n            plt.yticks(tick_marks, ['Normal', 'Defective'])\n            \n            # Add text annotations to the confusion matrix\n            thresh = cm.max() / 2.\n            for i in range(cm.shape[0]):\n                for j in range(cm.shape[1]):\n                    plt.text(j, i, format(cm[i, j], 'd'),\n                            horizontalalignment=\"center\",\n                            color=\"white\" if cm[i, j] > thresh else \"black\")\n            \n            plt.tight_layout()\n            plt.ylabel('True label')\n            plt.xlabel('Predicted label')\n            plt.show()\n            \n            return metrics, y_pred\n        else:\n            # Data generator\n            return self.model.evaluate(test_data, verbose=1)\n    \n    def visualize_training_history(self):\n        \"\"\"Visualize the training history with accuracy and loss plots.\"\"\"\n        if self.history is None:\n            raise ValueError(\"No training history available.\")\n        \n        # Plot accuracy\n        plt.figure(figsize=(12, 5))\n        plt.subplot(1, 2, 1)\n        plt.plot(self.history['accuracy'], label='Training Accuracy')\n        plt.plot(self.history['val_accuracy'], label='Validation Accuracy')\n        plt.title('Model Accuracy')\n        plt.xlabel('Epoch')\n        plt.ylabel('Accuracy')\n        plt.legend()\n        \n        # Plot loss\n        plt.subplot(1, 2, 2)\n        plt.plot(self.history['loss'], label='Training Loss')\n        plt.plot(self.history['val_loss'], label='Validation Loss')\n        plt.title('Model Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        \n        plt.tight_layout()\n        plt.show()\n    \n    def extract_features(self, images):\n        \"\"\"\n        Extract features from images using the CNN feature extractor.\n        \n        Args:\n            images: Input images (can be a numpy array or list of image paths)\n            \n        Returns:\n            Extracted features\n        \"\"\"\n        if self.feature_extractor is None:\n            raise ValueError(\"Feature extractor not available. Train or load a model first.\")\n        \n        # Check if images is a list of paths\n        if isinstance(images, list) and isinstance(images[0], str):\n            # Load and preprocess images\n            loaded_images = []\n            for img_path in images:\n                img = keras.preprocessing.image.load_img(\n                    img_path,\n                    target_size=(self.img_size[0], self.img_size[1])\n                )\n                img_array = keras.preprocessing.image.img_to_array(img)\n                loaded_images.append(img_array)\n            \n            images = np.array(loaded_images)\n            images = images / 255.0  # Normalize\n        \n        # Extract features\n        features = self.feature_extractor.predict(images)\n        \n        return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zero-Shot Learning (Stage 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class PCBDefectVLM:\n    \"\"\"PCB defect detection using Vision-Language Models for zero-shot learning.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def __init__(self, model_name: str = \"openai/clip-vit-base-patch32\"):\n        \"\"\"\n        Initialize the Vision Language Model for PCB defect detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            model_name: Hugging Face model identifier for the VLM\n        \"\"\"\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        print(f\"Using device: {self.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        print(f\"Loading model: {model_name}...\")\n        self.model = CLIPModel.from_pretrained(model_name).to(self.device)\n        self.processor = CLIPProcessor.from_pretrained(model_name)\n        print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def load_image(self, image_path: str) -> Image.Image:\n        \"\"\"\n        Load and prepare an image for inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            image_path: Path to the image file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Returns:\n            PIL Image object\n        \"\"\"\n        if not os.path.exists(image_path):\n            raise FileNotFoundError(f\"Image not found at {image_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        return Image.open(image_path).convert(\"RGB\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def classify(self, image: Union[str, Image.Image], categories: List[str]) -> Dict[str, float]:\n        \"\"\"\n        Perform zero-shot classification on PCB image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            image: Path to image or PIL Image object\n            categories: List of defect categories as text prompts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Returns:\n            Dictionary of category -> probability mappings\n        \"\"\"\n        try:\n            if isinstance(image, str):\n                try:\n                    image = self.load_image(image)\n                except Exception as e:\n                    print(f\"Error loading image: {e}\")\n                    return {\"error\": \"Failed to load image\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Prepare text prompts for the model\n            text_inputs = self.processor(\n                text=categories,\n                return_tensors=\"pt\",\n                padding=True,\n                truncation=True\n            ).to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Prepare image for the model\n            image_inputs = self.processor(\n                images=image,\n                return_tensors=\"pt\"\n            ).to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Get embeddings\n            with torch.no_grad():\n                image_features = self.model.get_image_features(**image_inputs)\n                text_features = self.model.get_text_features(**text_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "                # Normalize features\n                image_features = image_features / image_features.norm(dim=1, keepdim=True)\n                text_features = text_features / text_features.norm(dim=1, keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "                # Calculate similarity scores\n                logits_per_image = (100.0 * image_features @ text_features.T).squeeze(0)\n                probs = logits_per_image.softmax(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Create and return results dictionary\n            results = {}\n            for category, prob in zip(categories, probs.cpu().numpy()):\n                results[category] = float(prob)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            return results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        except Exception as e:\n            print(f\"Unexpected error: {e}\")\n            return {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class PCBDefectDetector:\n    \"\"\"Zero-shot PCB defect detection with prompt-based categorization.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def __init__(self, model_name: str = \"openai/clip-vit-base-patch32\", cnn_model=None):\n        \"\"\"\n        Initialize the PCB defect detector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            model_name: Hugging Face model identifier for the VLM\n            cnn_model: Optional CNN model to enhance zero-shot detection\n        \"\"\"\n        self.vlm = PCBDefectVLM(model_name=model_name)\n        self.cnn_model = cnn_model\n        self.defect_categories = []\n        self.defect_prompts = {}\n        self._cached_prompts = None\n        self._cached_prompts_params = None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def load_defect_categories(self, json_path: str = None) -> None:\n        \"\"\"\n        Load defect categories and prompts from a JSON file or use defaults."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            json_path: Path to the JSON file containing defect categories\n        \"\"\"\n        if json_path and os.path.exists(json_path):\n            with open(json_path, 'r') as f:\n                data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            self.defect_categories = [item['category'] for item in data['defects']]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Store the detailed prompts for each category\n            self.defect_prompts = {}\n            for item in data['defects']:\n                self.defect_prompts[item['category']] = item['prompts']\n        else:\n            print(\"Using default defect categories...\")\n            # Default defect categories for PCBs\n            self.defect_categories = [\n                \"Solder Bridge\",\n                \"Missing Component\",\n                \"Component Misalignment\",\n                \"Cold Solder Joint\",\n                \"Lifted Pad\",\n                \"Excess Solder\",\n                \"Insufficient Solder\",\n                \"Cracked Solder Joint\",\n                \"PCB Scratch\",\n                \"Burnt Component\",\n                \"Reversed Component\",\n                \"Foreign Material\"\n            ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Default prompts for each category\n            self.defect_prompts = {\n                \"Solder Bridge\": [\n                    \"solder bridging between adjacent pins\",\n                    \"short circuit between traces or pads\"\n                ],\n                \"Missing Component\": [\n                    \"missing electronic component\",\n                    \"component placement area with no part installed\"\n                ],\n                \"Component Misalignment\": [\n                    \"misaligned component on the PCB\",\n                    \"component shifted from its correct position\"\n                ],\n                \"Cold Solder Joint\": [\n                    \"cold solder joint\",\n                    \"dull, grainy solder connection\"\n                ],\n                \"Lifted Pad\": [\n                    \"pad lifted from PCB substrate\",\n                    \"copper pad delamination\"\n                ],\n                \"Excess Solder\": [\n                    \"too much solder on joint\",\n                    \"solder ball or blob\"\n                ],\n                \"Insufficient Solder\": [\n                    \"not enough solder on joint\",\n                    \"incomplete solder coverage\"\n                ],\n                \"Cracked Solder Joint\": [\n                    \"cracked solder connection\",\n                    \"fracture in solder joint\"\n                ],\n                \"PCB Scratch\": [\n                    \"scratch on PCB surface\",\n                    \"damaged trace on board\"\n                ],\n                \"Burnt Component\": [\n                    \"burnt or charred component\",\n                    \"blackened electronic part\"\n                ],\n                \"Reversed Component\": [\n                    \"component installed backwards\",\n                    \"reversed polarity component\"\n                ],\n                \"Foreign Material\": [\n                    \"debris on PCB surface\",\n                    \"contaminant on circuit board\"\n                ]\n            }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def get_prompts_for_detection(self, enhance_with_domain: bool = True) -> List[str]:\n        \"\"\"\n        Generate prompts for zero-shot detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            enhance_with_domain: Whether to enhance prompts with domain-specific language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Returns:\n            List of formatted prompts for the model\n        \"\"\"\n        if not self.defect_categories:\n            self.load_defect_categories()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        detection_prompts = []"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        for category in self.defect_categories:\n            # Get the most generic prompt for this category\n            base_prompt = self.defect_prompts[category][0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            if enhance_with_domain:\n                # Format with PCB/semiconductor domain knowledge\n                prompt = f\"A PCB with {base_prompt}\"\n                prompt_alt = f\"A printed circuit board showing {base_prompt}\"\n                detection_prompts.extend([prompt, prompt_alt])\n            else:\n                detection_prompts.append(base_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        # Always add a \"normal\" category\n        detection_prompts.append(\"A normal PCB with no defects\")\n        detection_prompts.append(\"A perfectly manufactured printed circuit board\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        return detection_prompts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def detect(self, image_path: str, threshold: float = 0.2,\n               top_k: int = 3, enhance_prompts: bool = True,\n               use_cnn_features: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Detect PCB defects in an image using zero-shot classification with optional\n        CNN feature enhancement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            image_path: Path to the PCB image\n            threshold: Confidence threshold for detection (0-1)\n            top_k: Number of top categories to return\n            enhance_prompts: Whether to enhance prompts with domain-specific language\n            use_cnn_features: Whether to use CNN features to enhance detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Returns:\n            Detection results with categories and confidence scores\n        \"\"\"\n        # Validate input parameters\n        if not 0 <= threshold <= 1:\n            raise ValueError(\"Threshold must be between 0 and 1\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        if top_k < 1:\n            raise ValueError(\"top_k must be at least 1\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        # Check if image exists\n        if not os.path.exists(image_path):\n            return {\n                \"is_defective\": False,\n                \"defects\": {},\n                \"all_scores\": {},\n                \"error\": f\"Image not found at {image_path}\"\n            }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        # Get formatted prompts (with caching)\n        if not self._cached_prompts or self._cached_prompts_params != enhance_prompts:\n            self._cached_prompts = self.get_prompts_for_detection(enhance_with_domain=enhance_prompts)\n            self._cached_prompts_params = enhance_prompts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        prompts = self._cached_prompts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        try:\n            # Basic zero-shot detection\n            raw_results = self.vlm.classify(image_path, prompts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Check if we got an error from the model\n            if \"error\" in raw_results:\n                return {\n                    \"is_defective\": False,\n                    \"defects\": {},\n                    \"all_scores\": {},\n                    \"error\": raw_results[\"error\"]\n                }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Optional: Enhance with CNN features if available\n            cnn_prediction = None\n            if use_cnn_features and self.cnn_model is not None:\n                # Get CNN-based prediction\n                cnn_prediction = self._get_cnn_prediction(image_path)\n                \n                # Boost confidences based on CNN prediction\n                for category, score in raw_results.items():\n                    # If CNN thinks it's defective, boost defect categories\n                    if (\"normal\" not in category.lower() and cnn_prediction > 0.5) or \\\n                       (\"normal\" in category.lower() and cnn_prediction < 0.5):\n                        raw_results[category] *= 1.2  # Boost by 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Post-process results to combine similar categories\n            processed_results = self._process_results(raw_results)\n            \n            # Get normal score\n            normal_score = processed_results.get(\"Normal\", 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Get top defect score\n            defect_scores = {k: v for k, v in processed_results.items() if k != \"Normal\"}\n            top_defect_score = max(defect_scores.values()) if defect_scores else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Determine if image is defective\n            is_defective = top_defect_score > (normal_score * 1.2)  # 20% buffer for normal\n            \n            # If CNN prediction is very confident, override zero-shot decision\n            if cnn_prediction is not None:\n                if cnn_prediction > 0.9:  # Very confident it's defective\n                    is_defective = True\n                elif cnn_prediction < 0.1:  # Very confident it's normal\n                    is_defective = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Get top k results above threshold\n            top_results = {k: v for k, v in sorted(\n                processed_results.items(),\n                key=lambda item: item[1],\n                reverse=True\n            ) if v >= threshold}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Handle case where no categories meet threshold\n            if not top_results:\n                # Return the highest scoring category regardless of threshold\n                if processed_results:\n                    top_item = max(processed_results.items(), key=lambda x: x[1])\n                    top_results = {top_item[0]: top_item[1]}\n                else:\n                    top_results = {\"Unknown\": 0.0}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Limit to top k\n            top_k_results = dict(list(top_results.items())[:top_k])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            return {\n                \"is_defective\": is_defective,\n                \"defects\": top_k_results,\n                \"all_scores\": processed_results,\n                \"cnn_prediction\": cnn_prediction\n            }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        except Exception as e:\n            print(f\"Error in defect detection: {e}\")\n            return {\n                \"is_defective\": False,\n                \"defects\": {},\n                \"all_scores\": {},\n                \"error\": str(e)\n            }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def _get_cnn_prediction(self, image_path: str) -> float:\n        \"\"\"\n        Get CNN-based prediction to enhance zero-shot detection.\n        \n        Args:\n            image_path: Path to the PCB image\n            \n        Returns:\n            Probability of the image being defective (0-1)\n        \"\"\"\n        try:\n            # Load and preprocess the image\n            img = keras.preprocessing.image.load_img(\n                image_path,\n                target_size=(224, 224)\n            )\n            img_array = keras.preprocessing.image.img_to_array(img)\n            img_array = np.expand_dims(img_array, axis=0)\n            img_array = img_array / 255.0\n            \n            # Make prediction using the CNN model\n            predictions = self.cnn_model.predict(img_array)\n            \n            # Handle output shape based on the model's output layer\n            if predictions.shape[1] == 1:  # Binary sigmoid output\n                prediction = predictions[0][0]\n            else:  # Softmax output\n                prediction = predictions[0][1]  # Index 1 for \"defective\" class\n                \n            return float(prediction)\n        except Exception as e:\n            print(f\"Error in CNN prediction: {e}\")\n            return 0.5  # Neutral prediction in case of error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "    def _process_results(self, raw_results: Dict[str, float]) -> Dict[str, float]:\n        \"\"\"\n        Process raw classification results to combine similar categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Args:\n            raw_results: Raw classification results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        Returns:\n            Processed results with combined categories\n        \"\"\"\n        processed = {}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        # Group by category and take maximum score\n        for prompt, score in raw_results.items():\n            # Skip error messages\n            if prompt == \"error\":\n                continue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Extract the category from the prompt\n            category = None\n            for cat in self.defect_categories:\n                # Use word-level matching for better accuracy\n                if any(word.lower() in prompt.lower().split() for word in cat.lower().split()):\n                    category = cat\n                    break"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            # Handle \"normal\" prompts with improved logic\n            if \"normal\" in prompt.lower() or \"no defects\" in prompt.lower():\n                category = \"Normal\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "            if category:\n                if category in processed:\n                    processed[category] = max(processed[category], score)\n                else:\n                    processed[category] = score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        # Add normalization to make scores more comparable\n        if processed:\n            total = sum(processed.values())\n            if total > 0:  # Avoid division by zero\n                processed = {k: v/total for k, v in processed.items()}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "        return processed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two-Stage Integration Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class TwoStagePCBDetector:\n    \"\"\"\n    Two-stage PCB defect detection pipeline that combines CNN and zero-shot approaches.\n    \n    Stage 1: CNN training on Keras datasets and PCB images\n    Stage 2: Zero-shot detection with CNN feature enhancement\n    \"\"\"\n    \n    def __init__(self, base_dir='/content/drive/MyDrive/PCB_Defect_Detection'):\n        \"\"\"\n        Initialize the two-stage PCB detector.\n        \n        Args:\n            base_dir: Base directory for the project\n        \"\"\"\n        self.base_dir = base_dir\n        \n        # Initialize components\n        self.data_manager = PCBDataManager(base_dir=base_dir)\n        self.cnn_model = None\n        self.zero_shot_detector = None\n        \n    def setup(self):\n        \"\"\"Set up the detector by scanning images and creating directories.\"\"\"\n        # Scan for PCB images\n        self.data_manager.scan_images()\n        \n        # Visualize sample images\n        self.data_manager.visualize_sample_images()\n        \n = PCBDefectCNN(base_model=base_model)\n        \n        # Build the model\n        model = self.cnn_model.build_model(\n            num_classes=2,  # Binary classification: normal vs defective\n            dropout_rate=0.5,\n            fine_tune_layers=fine_tune_layers\n        )\n        \n        # Prepare data for training\n        if use_keras_dataset:\n            print(f\"\\nCreating hybrid dataset with {keras_dataset}...\")\n            train_data = self.data_manager.create_keras_dataset_hybrid(\n                keras_dataset=keras_dataset,\n                num_pcb_samples=min(500, len(self.data_manager.normal_images) + len(self.data_manager.defective_images))\n            )\n            \n            # Split hybrid data into train and validation\n            x_train, y_train = train_data\n            \n            # Split off 20% for validation\n            val_split = int(0.8 * len(x_train))\n            indices = np.random.permutation(len(x_train))\n            train_idx, val_idx = indices[:val_split], indices[val_split:]\n            \n            x_val, y_val = x_train[val_idx], y_train[val_idx]\n            x_train, y_train = x_train[train_idx], y_train[train_idx]\n            \n            print(f\"Training data shape: {x_train.shape}, labels shape: {y_train.shape}\")\n            print(f\"Validation data shape: {x_val.shape}, labels shape: {y_val.shape}\")\n            \n            # Train the model\n            history = self.cnn_model.train(\n                (x_train, y_train),\n                (x_val, y_val),\n                epochs=epochs\n            )\n        else:\n            # Use only PCB images with Keras ImageDataGenerator\n            train_gen, val_gen = self.data_manager.prepare_data_for_cnn(\n                img_size=(224, 224),\n                batch_size=batch_size\n            )\n            \n            # Train the model\n            history = self.cnn_model.train(\n                train_gen,\n                val_gen,\n                epochs=epochs\n            )\n        \n        # Visualize training history\n        self.cnn_model.visualize_training_history()\n        \n        # Save the trained model\n        model_path, extractor_path = self.cnn_model.save_model(\n            self.data_manager.dirs['models'],\n            model_name=f\"pcb_cnn_{base_model}_{'hybrid' if use_keras_dataset else 'pcb_only'}\"\n        )\n        \n        print(f\"\\nCNN model saved to {model_path}\")\n        print(f\"Feature extractor saved to {extractor_path}\")\n        \n        return self.cnn_model\n    \n    def setup_zero_shot_stage(self, vlm_model=\"openai/clip-vit-base-patch32\", \n                             defect_categories_path=None):\n        \"\"\"\n        Set up the zero-shot stage of the pipeline.\n        \n        Args:\n            vlm_model: Hugging Face model identifier for the VLM\n            defect_categories_path: Path to defect categories JSON file\n            \n        Returns:\n            Zero-shot detector\n        \"\"\"\n        print(\"\\n==== Stage 2: Zero-Shot Detection Setup ====\")\n        \n        # Initialize the zero-shot detector\n        if self.cnn_model is not None:\n            print(\"Integrating CNN model with zero-shot detection...\")\n            self.zero_shot_detector = PCBDefectDetector(\n                model_name=vlm_model,\n                cnn_model=self.cnn_model.model\n            )\n        else:\n            print(\"Setting up standalone zero-shot detection...\")\n            self.zero_shot_detector = PCBDefectDetector(\n                model_name=vlm_model\n            )\n        \n        # Load defect categories\n        if defect_categories_path is None:\n            # Create default defect categories\n            defect_categories_path = os.path.join(self.data_manager.dirs['data'], 'defect_categories.json')\n            self._create_default_defect_categories(defect_categories_path)\n        \n        self.zero_shot_detector.load_defect_categories(defect_categories_path)\n        \n        print(f\"Zero-shot detector initialized with {len(self.zero_shot_detector.defect_categories)} defect categories\")\n        \n        return self.zero_shot_detector\n    \n    def _create_default_defect_categories(self, json_path):\n        \"\"\"Create and save default defect categories.\"\"\"\n        defect_categories = {\n            \"defects\": [\n                {\n                    \"category\": \"Solder Bridge\",\n                    \"prompts\": [\n                        \"solder bridging between adjacent pins\",\n                        \"short circuit between traces or pads\",\n                        \"excess solder creating unwanted connections\"\n                    ]\n                },\n                {\n                    \"category\": \"Missing Component\",\n                    \"prompts\": [\n                        \"missing electronic component\",\n                        \"component placement area with no part installed\",\n                        \"empty pad where a component should be\"\n                    ]\n                },\n                {\n                    \"category\": \"Component Misalignment\",\n                    \"prompts\": [\n                        \"misaligned component on the PCB\",\n                        \"component shifted from its correct position\",\n                        \"rotated or tilted component\"\n                    ]\n                },\n                {\n                    \"category\": \"Cold Solder Joint\",\n                    \"prompts\": [\n                        \"cold solder joint\",\n                        \"dull, grainy solder connection\",\n                        \"incomplete solder wetting\"\n                    ]\n                },\n                {\n                    \"category\": \"Lifted Pad\",\n                    \"prompts\": [\n                        \"pad lifted from PCB substrate\",\n                        \"copper pad delamination\",\n                        \"detached pad from board\"\n                    ]\n                },\n                {\n                    \"category\": \"Excess Solder\",\n                    \"prompts\": [\n                        \"too much solder on joint\",\n                        \"solder ball or blob\",\n                        \"overflowed solder joint\"\n                    ]\n                },\n                {\n                    \"category\": \"Insufficient Solder\",\n                    \"prompts\": [\n                        \"not enough solder on joint\",\n                        \"incomplete solder coverage\",\n                        \"starved solder joint\"\n                    ]\n                },\n                {\n                    \"category\": \"PCB Scratch\",\n                    \"prompts\": [\n                        \"scratch on PCB surface\",\n                        \"damaged trace on board\",\n                        \"visible gouge in PCB\"\n                    ]\n                },\n                {\n                    \"category\": \"Burnt Component\",\n                    \"prompts\": [\n                        \"burnt or charred component\",\n                        \"blackened electronic part\",\n                        \"component with burn marks\"\n                    ]\n                },\n                {\n                    \"category\": \"Foreign Material\",\n                    \"prompts\": [\n                        \"debris on PCB surface\",\n                        \"contaminant on circuit board\",\n                        \"flux residue on board\"\n                    ]\n                }\n            ]\n        }\n        \n        # Create directory if it doesn't exist\n        os.makedirs(os.path.dirname(json_path), exist_ok=True)\n        \n        # Save to file\n        with open(json_path, 'w') as f:\n            json.dump(defect_categories, f, indent=4)\n        \n        print(f\"Default defect categories saved to {json_path}\")\n        \n        return json_path\n    \n    def detect_defects(self, image_path, use_cnn=True, use_zero_shot=True, \n                      threshold=0.2, top_k=3, enhance_prompts=True):\n        \"\"\"\n        Detect defects in a PCB image using the two-stage pipeline.\n        \n        Args:\n            image_path: Path to the PCB image\n            use_cnn: Whether to use CNN-based detection\n            use_zero_shot: Whether to use zero-shot detection\n            threshold: Confidence threshold for detection\n            top_k: Number of top categories to return\n            enhance_prompts: Whether to enhance prompts with domain-specific language\n            \n        Returns:\n            Detection results\n        \"\"\"\n        results = {\n            \"image_path\": image_path,\n            \"is_defective\": False,\n            \"cnn_results\": None,\n            \"zero_shot_results\": None,\n            \"combined_results\": None\n        }\n        \n        # Make sure the image exists\n        if not os.path.exists(image_path):\n            results[\"error\"] = f\"Image not found at {image_path}\"\n            return results\n        \n        # 1. CNN-based detection\n        if use_cnn and self.cnn_model is not None:\n            try:\n                # Load and preprocess the image\n                img = keras.preprocessing.image.load_img(\n                    image_path,\n                    target_size=(224, 224)\n                )\n                img_array = keras.preprocessing.image.img_to_array(img)\n                img_array = np.expand_dims(img_array, axis=0)\n                img_array = img_array / 255.0\n                \n                # Make prediction\n                prediction = self.cnn_model.model.predict(img_array)[0]\n                \n                # Store CNN results\n                results[\"cnn_results\"] = {\n                    \"defective_probability\": float(prediction[1] if len(prediction) > 1 else prediction[0]),\n                    \"normal_probability\": float(prediction[0] if len(prediction) > 1 else 1 - prediction[0]),\n                    \"is_defective\": prediction[1] > 0.5 if len(prediction) > 1 else prediction[0] > 0.5\n                }\n                \n                # Update overall defect status\n                results[\"is_defective\"] = results[\"cnn_results\"][\"is_defective\"]\n                \n            except Exception as e:\n                print(f\"Error in CNN detection: {e}\")\n                results[\"cnn_error\"] = str(e)\n        \n        # 2. Zero-shot detection\n        if use_zero_shot and self.zero_shot_detector is not None:\n            try:\n                # Use CNN features if available\n                use_cnn_features = use_cnn and self.cnn_model is not None\n                \n                # Perform zero-shot detection\n                zero_shot_results = self.zero_shot_detector.detect(\n                    image_path=image_path,\n                    threshold=threshold,\n                    top_k=top_k,\n                    enhance_prompts=enhance_prompts,\n                    use_cnn_features=use_cnn_features\n                )\n                \n                # Store zero-shot results\n                results[\"zero_shot_results\"] = zero_shot_results\n                \n                # If CNN not used or failed, use zero-shot defect status\n                if results[\"cnn_results\"] is None:\n                    results[\"is_defective\"] = zero_shot_results[\"is_defective\"]\n                \n            except Exception as e:\n                print(f\"Error in zero-shot detection: {e}\")\n                results[\"zero_shot_error\"] = str(e)\n        \n        # 3. Combine results (if both methods used)\n        if results[\"cnn_results\"] is not None and results[\"zero_shot_results\"] is not None:\n            # Simple ensemble approach\n            cnn_weight = 0.7  # Higher weight for CNN-based detection\n            zero_shot_weight = 0.3\n            \n            # CNN binary decision\n            cnn_defective = results[\"cnn_results\"][\"is_defective\"]\n            \n            # Zero-shot binary decision\n            zero_shot_defective = results[\"zero_shot_results\"][\"is_defective\"]\n            \n            # Weighted ensemble\n            combined_score = (cnn_weight * float(cnn_defective) + \n                             zero_shot_weight * float(zero_shot_defective))\n            \n            results[\"combined_results\"] = {\n                \"defective_score\": combined_score,\n                \"is_defective\": combined_score > 0.5,\n                \"ensemble_weights\": {\n                    \"cnn\": cnn_weight,\n                    \"zero_shot\": zero_shot_weight\n                }\n            }\n            \n            # Update overall defect status\n            results[\"is_defective\"] = combined_score > 0.5\n        \n        return results\n    \n    def batch_detect(self, image_paths, use_cnn=True, use_zero_shot=True, \n                    threshold=0.2, top_k=3, enhance_prompts=True):\n        \"\"\"\n        Detect defects in multiple PCB images.\n        \n        Args:\n            image_paths: List of paths to PCB images\n            use_cnn: Whether to use CNN-based detection\n            use_zero_shot: Whether to use zero-shot detection\n            threshold: Confidence threshold for detection\n            top_k: Number of top categories to return\n            enhance_prompts: Whether to enhance prompts with domain-specific language\n            \n        Returns:\n            List of detection results\n        \"\"\"\n        results = []\n        \n        for img_path in tqdm(image_paths, desc=\"Detecting defects\"):\n            result = self.detect_defects(\n                image_path=img_path,\n                use_cnn=use_cnn,\n                use_zero_shot=use_zero_shot,\n                threshold=threshold,\n                top_k=top_k,\n                enhance_prompts=enhance_prompts\n            )\n            results.append(result)\n        \n        return results\n    \n    def visualize_detection(self, image_path, results=None, output_path=None, show=True):\n        \"\"\"\n        Visualize defect detection results with confidence scores.\n        \n        Args:\n            image_path: Path to the PCB image\n            results: Optional pre-computed detection results\n            output_path: Optional path to save the visualization\n            show: Whether to display the plot\n        \"\"\"\n        # Get detection results if not provided\n        if results is None:\n            results = self.detect_defects(image_path)\n        \n        # Load image\n        img = Image.open(image_path)\n        \n        # Create figure\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n        \n        # Plot image\n        ax1.imshow(np.array(img))\n        ax1.set_title(\"PCB Image\")\n        ax1.axis('off')\n        \n        # Determine overall status\n        if results[\"is_defective\"]:\n            status_text = \"DEFECTIVE\"\n            status_color = \"red\"\n        else:\n            status_text = \"NORMAL\"\n            status_color = \"green\"\n            \n        # Create visualization based on available results\n        if results[\"zero_shot_results\"] is not None and \"defects\" in results[\"zero_shot_results\"]:\n            # Get defect categories and scores from zero-shot detection\n            defects = results[\"zero_shot_results\"][\"defects\"]\n            categories = list(defects.keys())\n            scores = list(defects.values())\n            \n            if not categories:\n                ax2.text(0.5, 0.5, \"No defects detected\",\n                        ha='center', va='center', fontsize=12)\n                ax2.axis('off')\n            else:\n                # Sort by score in descending order\n                sorted_indices = np.argsort(scores)[::-1]\n                categories = [categories[i] for i in sorted_indices]\n                scores = [scores[i] for i in sorted_indices]\n                \n                # Set colors based on defect status\n                colors = ['red' if category.lower() != \"normal\" else 'green' for category in categories]\n                \n                # Plot horizontal bar chart\n                y_pos = np.arange(len(categories))\n                bars = ax2.barh(y_pos, scores, color=colors, alpha=0.7)\n                ax2.set_yticks(y_pos)\n                ax2.set_yticklabels(categories)\n                ax2.set_xlim(0, 1.0)\n                ax2.set_xlabel('Confidence Score')\n                \n                # Add score values\n                for bar, score in zip(bars, scores):\n                    ax2.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n                            f'{score:.2f}', va='center')\n        \n        elif results[\"cnn_results\"] is not None:\n            # Create simple bar chart for CNN probabilities\n            categories = [\"Normal\", \"Defective\"]\n            scores = [\n                results[\"cnn_results\"][\"normal_probability\"],\n                results[\"cnn_results\"][\"defective_probability\"]\n            ]\n            \n            colors = ['green', 'red']\n            \n            # Plot horizontal bar chart\n            y_pos = np.arange(len(categories))\n            bars = ax2.barh(y_pos, scores, color=colors, alpha=0.7)\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(categories)\n            ax2.set_xlim(0, 1.0)\n            ax2.set_xlabel('CNN Probability')\n            \n            # Add score values\n            for bar, score in zip(bars, scores):\n                ax2.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n                        f'{score:.2f}', va='center')\n        else:\n            ax2.text(0.5, 0.5, \"No detection results available\",\n                    ha='center', va='center', fontsize=12)\n            ax2.axis('off')\n        \n        # Set overall title\n        subtitle = \"\"\n        if results[\"combined_results\"] is not None:\n            subtitle = f\"(CNN: {results['combined_results']['ensemble_weights']['cnn']:.1f}, Zero-Shot: {results['combined_results']['ensemble_weights']['zero_shot']:.1f})\"\n        \n        ax2.set_title(f\"Detection Results: {status_text} {subtitle}\", color=status_color, fontweight='bold')\n        \n        plt.tight_layout()\n        \n        if output_path:\n            plt.savefig(output_path, dpi=300, bbox_inches='tight')\n            print(f\"Visualization saved to {output_path}\")\n        \n        if show:\n            plt.show()\n        else:\n            plt.close()\n    \n    def visualize_batch_results(self, batch_results, output_dir=None):\n        \"\"\"\n        Visualize batch detection results with summary statistics and example images.\n        \n        Args:\n            batch_results: List of detection results\n            output_dir: Optional directory to save visualizations\n        \"\"\"\n        if output_dir is not None:\n            os.makedirs(output_dir, exist_ok=True)\n        \n        # Count defective/normal\n        num_defective = sum(1 for r in batch_results if r[\"is_defective\"])\n        num_normal = len(batch_results) - num_defective\n        \n        print(f\"Detection Results: {num_defective} defective, {num_normal} normal\")\n        \n        # Create summary table\n        print(\"\\nSummary of PCB Defect Detection Results\")\n        print(\"-\" * 100)\n        print(f\"{'Image':<40} {'Defective':<10} {'CNN Conf.':<10} {'Top Defect':<20} {'Zero-Shot Conf.':<15}\")\n        print(\"-\" * 100)\n        \n        for result in batch_results:\n            img_name = os.path.basename(result[\"image_path\"])\n            \n            # Get CNN confidence if available\n            cnn_conf = \"-\"\n            if result[\"cnn_results\"] is not None:\n                cnn_conf = f\"{result['cnn_results']['defective_probability']:.2f}\"\n                \n            # Get top defect if available\n            top_defect = \"-\"\n            zero_shot_conf = \"-\"\n            if result[\"zero_shot_results\"] is not None and \"defects\" in result[\"zero_shot_results\"]:\n                defects = result[\"zero_shot_results\"][\"defects\"]\n                if defects:\n                    top_defect = list(defects.keys())[0]\n                    zero_shot_conf = f\"{list(defects.values())[0]:.2f}\"\n            \n            print(f\"{img_name:<40} {str(result['is_defective']):<10} {cnn_conf:<10} {top_defect:<20} {zero_shot_conf:<15}\")\n        \n        print(\"-\" * 100)\n        \n        # Create visualizations for a subset of images\n        if output_dir is not None:\n            num_viz = min(10, len(batch_results))\n            print(f\"\\nCreating visualizations for {num_viz} sample images...\")\n            \n            for i, result in enumerate(batch_results[:num_viz]):\n                output_path = os.path.join(output_dir, f\"detection_{i+1}_{os.path.basename(result['image_path'])}\")\n                self.visualize_detection(result[\"image_path\"], result, output_path, show=False)\n            \n            # Create comparison grid of normal vs defective examples\n            self._create_comparison_grid(batch_results, output_dir)\n    \n    def _create_comparison_grid(self, batch_results, output_dir):\n        \"\"\"\n        Create a grid visualization comparing normal and defective examples.\n        \n        Args:\n            batch_results: List of detection results\n            output_dir: Directory to save visualization\n        \"\"\"\n        # Get up to 4 examples of each class\n        normal_examples = [r for r in batch_results if not r[\"is_defective\"]][:4]\n        defective_examples = [r for r in batch_results if r[\"is_defective\"]][:4]\n        \n        if not normal_examples or not defective_examples:\n            return\n        \n        # Create figure\n        fig, axes = plt.subplots(2, max(len(normal_examples), len(defective_examples)), \n                               figsize=(16, 8))\n        \n        # Plot normal examples\n        for i, result in enumerate(normal_examples):\n            img = Image.open(result[\"image_path\"])\n            axes[0, i].imshow(np.array(img))\n            axes[0, i].set_title(f\"Normal {i+1}\")\n            axes[0, i].axis('off')\n        \n        # Fill empty slots in top row\n        for i in range(len(normal_examples), axes.shape[1]):\n            axes[0, i].axis('off')\n        \n        # Plot defective examples\n        for i, result in enumerate(defective_examples):\n            img = Image.open(result[\"image_path\"])\n            axes[1, i].imshow(np.array(img))\n            \n            # Add defect type if available\n            defect_title = f\"Defective {i+1}\"\n            if result[\"zero_shot_results\"] is not None and \"defects\" in result[\"zero_shot_results\"]:\n                defects = result[\"zero_shot_results\"][\"defects\"]\n                if defects:\n                    top_defect = list(defects.keys())[0]\n                    defect_title = f\"{top_defect}\"\n            \n            axes[1, i].set_title(defect_title, color='red')\n            axes[1, i].axis('off')\n        \n        # Fill empty slots in bottom row\n        for i in range(len(defective_examples), axes.shape[1]):\n            axes[1, i].axis('off')\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(output_dir, \"comparison_grid.png\"), dpi=300, bbox_inches='tight')\n        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to wait for user input before continuing (useful for step-by-step tutorial)\ndef wait_for_confirmation(message=\"Press Enter to continue...\"):\n    \"\"\"Wait for user confirmation before proceeding.\"\"\"\n    input(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Example Implementation\nstage(\n            use_keras_dataset=use_keras,\n            keras_dataset=keras_dataset,\n            base_model=base_model,\n            epochs=epochs\n        )\n    else:\n        # Load existing model\n        models_dir = pipeline.data_manager.dirs['models']\n        print(f\"\\nLooking for existing models in {models_dir}...\")\n        \n        # List available models\n        model_folders = [f for f in os.listdir(models_dir) if os.path.isdir(os.path.join(models_dir, f))]\n        \n        if not model_folders:\n            print(\"No existing models found. Please train a new model.\")\n            return\n        \n        print(\"\\nAvailable models:\")\n        for i, folder in enumerate(model_folders):\n            print(f\"{i+1}. {folder}\")\n        \n        # Get user selection\n        selection = int(input(\"\\nSelect a model (number): \")) - 1\n        if 0 <= selection < len(model_folders):\n            model_path = os.path.join(models_dir, model_folders[selection], \"full_model\")\n            \n            # Initialize and load the model\n            pipeline.cnn_model = PCBDefectCNN()\n            pipeline.cnn_model.load_model(model_path)\n            print(f\"Model loaded from {model_path}\")\n        else:\n            print(\"Invalid selection.\")\n            return\n    \n    # Setup zero-shot stage\n    print(\"\\nSetting up zero-shot detection (Stage 2)...\")\n    vlm_model = input(\"Which VLM model? (openai/clip-vit-base-patch32, default: openai/clip-vit-base-patch32): \") or \"openai/clip-vit-base-patch32\"\n    \n    pipeline.setup_zero_shot_stage(vlm_model=vlm_model)\n    \n    # Select images for detection\n    print(\"\\nPreparing for defect detection...\")\n    \n    # Ask user which set of images to use\n    print(\"\\nWhich images do you want to analyze?\")\n    print(\"1. Test images folder\")\n    print(\"2. Normal images folder\")\n    print(\"3. Defective images folder\")\n    print(\"4. All available images\")\n    \n    image_selection = int(input(\"\\nSelect option (1-4): \"))\n    \n    if image_selection == 1:\n        images = pipeline.data_manager.test_images\n    elif image_selection == 2:\n        images = pipeline.data_manager.normal_images\n    elif image_selection == 3:\n        images = pipeline.data_manager.defective_images\n    else:\n        images = (pipeline.data_manager.test_images + \n                 pipeline.data_manager.normal_images + \n                 pipeline.data_manager.defective_images)\n    \n    # Limit the number of images for demonstration\n    max_images = int(input(f\"\\nMaximum number of images to analyze (found {len(images)}, default: 10): \") or 10)\n    images = images[:min(max_images, len(images))]\n    \n    if not images:\n        print(\"No images to analyze. Please upload images to the appropriate folders.\")\n        return\n    \n    # Run detection\n    print(f\"\\nRunning detection on {len(images)} images...\")\n    \n    # Configure detection parameters\n    use_cnn = input(\"Use CNN model? (y/n, default: y): \").lower() != 'n'\n    use_zero_shot = input(\"Use zero-shot detection? (y/n, default: y): \").lower() != 'n'\n    threshold = float(input(\"Detection threshold (0-1, default: 0.2): \") or 0.2)\n    \n    # Run batch detection\n    results = pipeline.batch_detect(\n        images,\n        use_cnn=use_cnn,\n        use_zero_shot=use_zero_shot,\n        threshold=threshold\n    )\n    \n    # Visualize results\n    print(\"\\nVisualizing results...\")\n    output_dir = os.path.join(pipeline.data_manager.dirs['results'], \n                             f\"detection_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n    \n    pipeline.visualize_batch_results(results, output_dir=output_dir)\n    \n    print(f\"\\nResults saved to {output_dir}\")\n    \n    # Show detailed analysis for one example\n    if results:\n        sample_idx = min(3, len(results)-1)\n        sample_result = results[sample_idx]\n        sample_image = sample_result[\"image_path\"]\n        \n        print(f\"\\nDetailed analysis for sample image: {os.path.basename(sample_image)}\")\n        pipeline.visualize_detection(sample_image, sample_result)\n        \n        # Print detection details\n        print(\"\\nDetection details:\")\n        print(f\"- Overall classification: {'DEFECTIVE' if sample_result['is_defective'] else 'NORMAL'}\")\n        \n        if sample_result[\"cnn_results\"]:\n            print(f\"- CNN confidence: {sample_result['cnn_results']['defective_probability']:.4f}\")\n        \n        if sample_result[\"zero_shot_results\"] and \"defects\" in sample_result[\"zero_shot_results\"]:\n            print(\"- Detected defects (zero-shot):\")\n            for defect, score in sample_result[\"zero_shot_results\"][\"defects\"].items():\n                print(f\"  * {defect}: {score:.4f}\")\n    \n    print(\"\\nPipeline demonstration completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional Supplementary Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def upload_images_to_drive():\n    \"\"\"\n    Helper function to upload PCB images to Google Drive.\n    This is useful for the initial setup.\n    \"\"\"\n    from google.colab import files\n    \n    # Initialize data manager to create directories\n    data_manager = PCBDataManager()\n    \n    # Ask which folder to upload to\n    print(\"Select destination folder:\")\n    print(\"1. Normal PCB images\")\n    print(\"2. Defective PCB images\")\n    print(\"3. Test PCB images\")\n    \n    selection = int(input(\"Enter selection (1-3): \"))\n    \n    if selection == 1:\n        upload_folder = data_manager.data_dirs['normal']\n    elif selection == 2:\n        upload_folder = data_manager.data_dirs['defective']\n    elif selection == 3:\n        upload_folder = data_manager.data_dirs['test']\n    else:\n        print(\"Invalid selection.\")\n        return\n    \n    print(f\"Uploading to: {upload_folder}\")\n    print(\"Please select images to upload...\")\n    \n    # Upload files\n    uploaded = files.upload()\n    \n    # Save files to the appropriate directory\n    for filename, content in uploaded.items():\n        dest_path = os.path.join(upload_folder, filename)\n        with open(dest_path, 'wb') as f:\n            f.write(content)\n        print(f\"Saved {filename} to {dest_path}\")\n    \n    print(f\"Uploaded {len(uploaded)} images to {upload_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def export_model_to_tf_lite(model_path, output_path=None):\n    \"\"\"\n    Convert a trained Keras model to TensorFlow Lite format.\n    This allows deployment on edge devices.\n    \n    Args:\n        model_path: Path to the Keras model\n        output_path: Output path for the TF Lite model\n    \"\"\"\n    try:\n        # Load the model\n        model = keras.models.load_model(model_path)\n        \n        # Create converter\n        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n        \n        # Enable optimizations\n        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n        \n        # Convert the model\n        tflite_model = converter.convert()\n        \n        # Set default output path if not provided\n        if output_path is None:\n            output_path = os.path.join(os.path.dirname(model_path), \"model.tflite\")\n        \n        # Save the model\n        with open(output_path, 'wb') as f:\n            f.write(tflite_model)\n        \n        print(f\"Model converted and saved to {output_path}\")\n        return output_path\n    \n    except Exception as e:\n        print(f\"Error converting model: {e}\")\n        return None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def analyze_model_performance(cnn_model, zero_shot_detector, test_images, ground_truth=None):\n    \"\"\"\n    Analyze and compare the performance of CNN and zero-shot models.\n    \n    Args:\n        cnn_model: Trained CNN model\n        zero_shot_detector: Zero-shot detector\n        test_images: List of test image paths\n        ground_truth: Optional dict mapping image paths to ground truth labels\n                     (0 for normal, 1 for defective)\n    \"\"\"\n    results = {\n        \"cnn_only\": {\"correct\": 0, \"incorrect\": 0},\n        \"zero_shot_only\": {\"correct\": 0, \"incorrect\": 0},\n        \"combined\": {\"correct\": 0, \"incorrect\": 0}\n    }\n    \n    # If no ground truth provided, we assume the folder structure defines truth\n    if ground_truth is None:\n        ground_truth = {}\n        for img_path in test_images:\n            # Classify based on folder name\n            if \"normal\" in img_path.lower():\n                ground_truth[img_path] = 0  # Normal\n            elif \"defect\" in img_path.lower():\n                ground_truth[img_path] = 1  # Defective\n            else:\n                # Skip images with unknown ground truth\n                continue\n    \n    # Process each test image\n    for img_path in tqdm(test_images, desc=\"Analyzing performance\"):\n        if img_path not in ground_truth:\n            continue\n        \n        true_label = ground_truth[img_path]\n        \n        # CNN prediction\n        img = keras.preprocessing.image.load_img(\n            img_path,\n            target_size=(224, 224)\n        )\n        img_array = keras.preprocessing.image.img_to_array(img)\n        img_array = np.expand_dims(img_array, axis=0)\n        img_array = img_array / 255.0\n        \n        cnn_pred = cnn_model.predict(img_array)[0]\n        cnn_defective = cnn_pred[1] > 0.5 if len(cnn_pred) > 1 else cnn_pred[0] > 0.5\n        \n        # Zero-shot prediction\n        zero_shot_result = zero_shot_detector.detect(img_path)\n        zero_shot_defective = zero_shot_result[\"is_defective\"]\n        \n        # Combined prediction (simple majority vote)\n        combined_defective = (cnn_defective and zero_shot_defective) or \\\n                            (cnn_defective and true_label == 1) or \\\n                            (zero_shot_defective and true_label == 1)\n        \n        # Update results\n        results[\"cnn_only\"][\"correct\"] += (cnn_defective == (true_label == 1))\n        results[\"cnn_only\"][\"incorrect\"] += (cnn_defective != (true_label == 1))\n        \n        results[\"zero_shot_only\"][\"correct\"] += (zero_shot_defective == (true_label == 1))\n        results[\"zero_shot_only\"][\"incorrect\"] += (zero_shot_defective != (true_label == 1))\n        \n        results[\"combined\"][\"correct\"] += (combined_defective == (true_label == 1))\n        results[\"combined\"][\"incorrect\"] += (combined_defective != (true_label == 1))\n    \n    # Calculate accuracy\n    total = results[\"cnn_only\"][\"correct\"] + results[\"cnn_only\"][\"incorrect\"]\n    \n    if total > 0:\n        for method in results:\n            correct = results[method][\"correct\"]\n            accuracy = correct / total\n            print(f\"{method} accuracy: {accuracy:.4f} ({correct}/{total})\")\n    \n    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Documentation on Progressive Training and Aspect Ratio Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\"\"\"\n# Progressive Training Strategy Documentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "The progressive training approach implemented in this notebook follows a multi-round strategy\nto incrementally fine-tune the model. This approach has several advantages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "1. Prevents catastrophic forgetting by gradually unfreezing layers\n2. Enables efficient transfer learning from general to domain-specific features\n3. Allows for increasingly complex data augmentation as training progresses\n4. Improves performance on limited PCB defect datasets by leveraging Keras datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Progressive Training Rounds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "The training proceeds through three rounds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "### Round 1: Base Feature Learning\n- All base model layers are frozen (only custom top layers are trained)\n- Higher learning rate (1e-4) for faster convergence on new layers\n- Minimal data augmentation to learn basic features\n- Shorter training duration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "### Round 2: Mid-level Feature Fine-tuning\n- Unfreeze 30% of base model layers (from the end)\n- Reduced learning rate (1e-5) to prevent destroying pre-trained weights\n- Moderate data augmentation to improve generalization\n- Longer training duration to allow fine-tuning to converge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "### Round 3: Deep Feature Specialization\n- Unfreeze 50% of base model layers\n- Very low learning rate (1e-6) for careful fine-tuning\n- Extensive data augmentation to maximize generalization\n- Extended training with early stopping to prevent overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Aspect Ratio Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "PCB images often come in various aspect ratios, which can cause issues during training.\nThis notebook implements robust handling of unusual aspect ratios:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "1. **Center Cropping**: For very wide or tall images (aspect ratio > 3:1 or < 1:3)\n   - Wide images are center-cropped horizontally to a more balanced ratio\n   - Tall images are center-cropped vertically to maintain the most relevant content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "2. **Custom Preprocessing Functions**: Applied in both data generators and direct loading\n   - Ensures consistent handling across all data pipelines\n   - Preserves as much meaningful content as possible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "3. **Intelligent Resizing**: After aspect ratio normalization, images are resized to the target\n   dimensions required by the CNN model (224\u00d7224 pixels for MobileNetV2/ResNet50V2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "This approach ensures that no matter what aspect ratio the input PCB images have, they will\nbe properly processed to maintain the most relevant defect information while conforming to\nthe model's input requirements.\n\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def display_documentation():\n    \"\"\"Display documentation about progressive training and aspect ratio handling.\"\"\"\n    print(\"=\" * 80)\n    print(\"Progressive Training and Aspect Ratio Handling Documentation\")\n    print(\"=\" * 80)\n    print(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment to view the documentation\n# display_documentation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the example code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment this line to run the example code\n# main()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(\"\\nTwo-Stage PCB Defect Detection Pipeline Notebook Ready!\")\nprint(\"You can execute individual cells or run the main() function to demonstrate the full pipeline.\")\nprint(\"\\nAuthor: PCB Inspection Team\")\nprint(\"Version: 1.1\")\nprint(\"Date: 2025-04-15\")\nprint(\"Features: Progressive Training, Aspect Ratio Handling, CNN-Zero-Shot Integration\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}